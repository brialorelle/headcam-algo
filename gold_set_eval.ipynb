{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/users/agrawalk/miniconda2/envs/headcam/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This notebook contains code for drawing face-detected and random samples from a video, \n",
    "annotating on face/no face, and calculating precision, recall, and F-score.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import ntpath\n",
    "\n",
    "from detector import FaceDetector\n",
    "from gold_sample_processing import (create_sample_json, annotate_sample, run_detector_on_sample, \n",
    "                                    incorporate_openpose_output, display_prf, display_prf2)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!which python # should be /home/users/agrawalk/miniconda2/envs/headcam/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: sq: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'Submitted batch job 38858098\\n', b'')\n",
      "(b'Submitted batch job 38858099\\n', b'')\n",
      "(b'Submitted batch job 38858100\\n', b'')\n"
     ]
    }
   ],
   "source": [
    "#1. Extract frames with ffmpeg\n",
    "SCRATCH = os.path.expandvars('$SCRATCH')\n",
    "VID_NAMES = ['053113-1', '2013-10-27-part2', '061413-3',\n",
    "             '2014-06-18-part2', '061713-1', '2014-01-01-part2']\n",
    "VID_PATHS = [os.path.join(SCRATCH, 'testvideos', f'{vid_name}.AVI') \n",
    "             for vid_name in VID_NAMES]\n",
    "cmd = ('sbatch -p normal,hns -t 1:30:00 '\n",
    "       '--mail-type=FAIL --mail-user=agrawalk@stanford.edu '\n",
    "       '--wrap=\"python extract_frames.py {}\"')\n",
    "\n",
    "for vid_path in VID_PATHS[:3]:\n",
    "    p = subprocess.Popen(cmd.format(vid_path), shell=True, \n",
    "                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(p.communicate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Run MTCNN on 10000 frames of each video\n",
    "#TODO: add case to check if output json exists, and ask for confirmation to overwrite\n",
    "MASTER_JSON_PATH = os.path.join(SCRATCH, 'headcam-algo', 'gold_set.json')\n",
    "OUTPUT = os.path.join(SCRATCH, 'headcam_algo', 'output'\n",
    "FRAME_DIRS = [os.path.join(OUTPUT, f'{vid_name}_frames') for vid_name in VID_NAMES]\n",
    "\n",
    "cmd = ('sbatch -p normal,hns -c 8 -t 1:30:00 '\n",
    "       '--mail-type=FAIL --mail-user=agrawalk@stanford.edu '\n",
    "       '--wrap=\"python detect_faces_simple.py {}\"')\n",
    "                      \n",
    "for frame_dir in FRAME_DIRS:\n",
    "    p = subprocess.Popen(cmd.format(frame_dir), shell=True, \n",
    "                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(p.communicate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. select a random sample of 200 face-detected, 200 random frames from each video in the dataframe\n",
    "#e.g. if 6 videos in JSON, creates a sample dataframe of size (200 + 200)*6 = 2400 frames\n",
    "#TODO: add case to check if output json exists, and ask for confirmation to overwrite\n",
    "SAMPLE_JSON_PATH = os.path.join(SCRATCH, 'headcam-algo', 'gold_set_sample.json')\n",
    "\n",
    "create_sample_json(MASTER_JSON_PATH, SAMPLE_JSON_PATH, sample_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4a. run + add detections for additional detectors to dataframe.\n",
    "\n",
    "for det_name in ['vj']:\n",
    "    run_detector_on_sample(det_name, FRAMES_DIR, SAMPLE_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4b. Hand-annotate for face (y/n) on the sample. Save annotations to dataframe.\n",
    "#TODO: add case to check if annotation column exists, and ask for confirmation to overwrite\n",
    "annotate_frames(OUTPUT, SAMPLE_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5a. Run openpose on videos\n",
    "OPENPOSE_OUTPUT = os.path.join(SCRATCH, 'headcam-algo', 'openpose_json_output')\n",
    "\n",
    "cmd = ('sbatch -p gpu --gres gpu:1 -t 5:00:00 --mem 8G '\n",
    "       '--mail-type=FAIL --mail-user=agrawalk@stanford.edu '\n",
    "       '--wrap=\"singularity exec --nv $SINGULARITY_CACHEDIR/openpose-latest.img bash -c '\n",
    "       'cd /openpose-master && ./build/examples/openpose/openpose.bin '\n",
    "       '--no_display true '\n",
    "       '--render_pose 0 '\n",
    "       '--video {0} '\n",
    "       '--frame_rotate 180 '\n",
    "       '--face ' # maybe don't want this\n",
    "       '--hand ' # probably don't want this\n",
    "       '--write_keypoint_json {1}')\n",
    "\n",
    "for vid_path in VID_PATHS:\n",
    "    openpose_vid_output = os.path.join(OPENPOSE_OUTPUT, ntpath.basename(vid)[:-4])\n",
    "    #TODO: add case to check if output dir exists, and ask for confirmation to overwrite\n",
    "    process = subprocess.run(cmd.format(vid_path, openpose_vid_output), shell=True, \n",
    "                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(process.stdout.decode('utf-8')) #Output of job submission command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5b. add columns to the dataframe for the openpose keypoints\n",
    "#TODO: add case to check if openpose column exists, and ask for confirmation to overwrite\n",
    "incorporate_openpose_output(SAMPLE_JSON_PATH, OPENPOSE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETECTOR: vj\n",
      "\tGROUP: face (1200 frames)\n",
      "\tprecision: 0.94, recall: 0.39, F1: 0.55\n",
      "\n",
      "\tVID: 053113-1 (200 frames)\n",
      "\tprecision: 0.89, recall: 0.65, F1: 0.75\n",
      "\n",
      "\tVID: 2014-06-18-part2 (200 frames)\n",
      "\tprecision: 0.4, recall: 0.03, F1: 0.05\n",
      "\n",
      "\tVID: 061413-3 (200 frames)\n",
      "\tprecision: 1.0, recall: 0.55, F1: 0.71\n",
      "\n",
      "\tVID: 2013-10-27-part2 (200 frames)\n",
      "\tprecision: 0.98, recall: 0.4, F1: 0.56\n",
      "\n",
      "\tVID: 061713-1 (200 frames)\n",
      "\tprecision: 0.94, recall: 0.2, F1: 0.32\n",
      "\n",
      "\tVID: 2014-01-01-part2 (200 frames)\n",
      "\tprecision: 0.85, recall: 0.35, F1: 0.5\n",
      "\n",
      "\tGROUP: random (1200 frames)\n",
      "\tprecision: 0.69, recall: 0.15, F1: 0.25\n",
      "\n",
      "\tVID: 053113-1 (200 frames)\n",
      "\tprecision: 0.47, recall: 0.25, F1: 0.33\n",
      "\n",
      "\tVID: 2014-06-18-part2 (200 frames)\n",
      "\tprecision: 0.0, recall: 0.0, F1: 0.0\n",
      "\n",
      "\tVID: 061413-3 (200 frames)\n",
      "\tprecision: 0.93, recall: 0.25, F1: 0.39\n",
      "\n",
      "\tVID: 2013-10-27-part2 (200 frames)\n",
      "\tprecision: 0.65, recall: 0.22, F1: 0.33\n",
      "\n",
      "\tVID: 061713-1 (200 frames)\n",
      "\tprecision: 0.83, recall: 0.06, F1: 0.11\n",
      "\n",
      "\tVID: 2014-01-01-part2 (200 frames)\n",
      "\tprecision: 0.25, recall: 0.03, F1: 0.05\n",
      "\n",
      "DETECTOR: mtcnn\n",
      "\tGROUP: face (1200 frames)\n",
      "\tprecision: 0.64, recall: 1.0, F1: 0.78\n",
      "\n",
      "\tVID: 053113-1 (200 frames)\n",
      "\tprecision: 0.54, recall: 1.0, F1: 0.7\n",
      "\n",
      "\tVID: 2014-06-18-part2 (200 frames)\n",
      "\tprecision: 0.38, recall: 1.0, F1: 0.55\n",
      "\n",
      "\tVID: 061413-3 (200 frames)\n",
      "\tprecision: 0.98, recall: 1.0, F1: 0.99\n",
      "\n",
      "\tVID: 2013-10-27-part2 (200 frames)\n",
      "\tprecision: 0.81, recall: 1.0, F1: 0.9\n",
      "\n",
      "\tVID: 061713-1 (200 frames)\n",
      "\tprecision: 0.74, recall: 1.0, F1: 0.85\n",
      "\n",
      "\tVID: 2014-01-01-part2 (200 frames)\n",
      "\tprecision: 0.41, recall: 1.0, F1: 0.58\n",
      "\n",
      "\tGROUP: random (1200 frames)\n",
      "\tprecision: 0.71, recall: 0.38, F1: 0.49\n",
      "\n",
      "\tVID: 053113-1 (200 frames)\n",
      "\tprecision: 0.4, recall: 0.57, F1: 0.47\n",
      "\n",
      "\tVID: 2014-06-18-part2 (200 frames)\n",
      "\tprecision: 0.58, recall: 0.31, F1: 0.4\n",
      "\n",
      "\tVID: 061413-3 (200 frames)\n",
      "\tprecision: 0.95, recall: 0.41, F1: 0.57\n",
      "\n",
      "\tVID: 2013-10-27-part2 (200 frames)\n",
      "\tprecision: 0.83, recall: 0.59, F1: 0.69\n",
      "\n",
      "\tVID: 061713-1 (200 frames)\n",
      "\tprecision: 0.79, recall: 0.32, F1: 0.46\n",
      "\n",
      "\tVID: 2014-01-01-part2 (200 frames)\n",
      "\tprecision: 0.0, recall: 0.0, F1: 0.0\n",
      "\n",
      "DETECTOR: openpose\n",
      "\tGROUP: face (1200 frames)\n",
      "\tprecision: 0.8, recall: 1.0, F1: 0.89\n",
      "\n",
      "\tVID: 053113-1 (200 frames)\n",
      "\tprecision: 0.79, recall: 1.0, F1: 0.88\n",
      "\n",
      "\tVID: 2014-06-18-part2 (200 frames)\n",
      "\tprecision: 0.7, recall: 0.97, F1: 0.82\n",
      "\n",
      "\tVID: 061413-3 (200 frames)\n",
      "\tprecision: 0.98, recall: 1.0, F1: 0.99\n",
      "\n",
      "\tVID: 2013-10-27-part2 (200 frames)\n",
      "\tprecision: 0.96, recall: 1.0, F1: 0.98\n",
      "\n",
      "\tVID: 061713-1 (200 frames)\n",
      "\tprecision: 0.78, recall: 1.0, F1: 0.88\n",
      "\n",
      "\tVID: 2014-01-01-part2 (200 frames)\n",
      "\tprecision: 0.49, recall: 1.0, F1: 0.65\n",
      "\n",
      "\tGROUP: random (1200 frames)\n",
      "\tprecision: 0.5, recall: 0.93, F1: 0.65\n",
      "\n",
      "\tVID: 053113-1 (200 frames)\n",
      "\tprecision: 0.26, recall: 0.89, F1: 0.41\n",
      "\n",
      "\tVID: 2014-06-18-part2 (200 frames)\n",
      "\tprecision: 0.44, recall: 0.94, F1: 0.6\n",
      "\n",
      "\tVID: 061413-3 (200 frames)\n",
      "\tprecision: 0.74, recall: 0.97, F1: 0.84\n",
      "\n",
      "\tVID: 2013-10-27-part2 (200 frames)\n",
      "\tprecision: 0.72, recall: 0.83, F1: 0.77\n",
      "\n",
      "\tVID: 061713-1 (200 frames)\n",
      "\tprecision: 0.53, recall: 0.99, F1: 0.69\n",
      "\n",
      "\tVID: 2014-01-01-part2 (200 frames)\n",
      "\tprecision: 0.3, recall: 0.89, F1: 0.45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_JSON_PATH  = '/scratch/users/agrawalk/headcam-algo/tests/gold_set_sample.json'\n",
    "display_prf(SAMPLE_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VID: 053113-1 (400 frames)\n",
      "\tDETECTOR: vj\n",
      "\t[face] precision: 0.89, recall: 0.65, F1: 0.75\n",
      "\n",
      "\t[random] precision: 0.47, recall: 0.25, F1: 0.33\n",
      "\n",
      "\n",
      "\tDETECTOR: mtcnn\n",
      "\t[face] precision: 0.54, recall: 1.0, F1: 0.7\n",
      "\n",
      "\t[random] precision: 0.4, recall: 0.57, F1: 0.47\n",
      "\n",
      "\n",
      "\tDETECTOR: openpose\n",
      "\t[face] precision: 0.79, recall: 1.0, F1: 0.88\n",
      "\n",
      "\t[random] precision: 0.26, recall: 0.89, F1: 0.41\n",
      "\n",
      "\n",
      "VID: 2014-06-18-part2 (400 frames)\n",
      "\tDETECTOR: vj\n",
      "\t[face] precision: 0.4, recall: 0.03, F1: 0.05\n",
      "\n",
      "\t[random] precision: 0.0, recall: 0.0, F1: 0.0\n",
      "\n",
      "\n",
      "\tDETECTOR: mtcnn\n",
      "\t[face] precision: 0.38, recall: 1.0, F1: 0.55\n",
      "\n",
      "\t[random] precision: 0.58, recall: 0.31, F1: 0.4\n",
      "\n",
      "\n",
      "\tDETECTOR: openpose\n",
      "\t[face] precision: 0.7, recall: 0.97, F1: 0.82\n",
      "\n",
      "\t[random] precision: 0.44, recall: 0.94, F1: 0.6\n",
      "\n",
      "\n",
      "VID: 061413-3 (400 frames)\n",
      "\tDETECTOR: vj\n",
      "\t[face] precision: 1.0, recall: 0.55, F1: 0.71\n",
      "\n",
      "\t[random] precision: 0.93, recall: 0.25, F1: 0.39\n",
      "\n",
      "\n",
      "\tDETECTOR: mtcnn\n",
      "\t[face] precision: 0.98, recall: 1.0, F1: 0.99\n",
      "\n",
      "\t[random] precision: 0.95, recall: 0.41, F1: 0.57\n",
      "\n",
      "\n",
      "\tDETECTOR: openpose\n",
      "\t[face] precision: 0.98, recall: 1.0, F1: 0.99\n",
      "\n",
      "\t[random] precision: 0.74, recall: 0.97, F1: 0.84\n",
      "\n",
      "\n",
      "VID: 2013-10-27-part2 (400 frames)\n",
      "\tDETECTOR: vj\n",
      "\t[face] precision: 0.98, recall: 0.4, F1: 0.56\n",
      "\n",
      "\t[random] precision: 0.65, recall: 0.22, F1: 0.33\n",
      "\n",
      "\n",
      "\tDETECTOR: mtcnn\n",
      "\t[face] precision: 0.81, recall: 1.0, F1: 0.9\n",
      "\n",
      "\t[random] precision: 0.83, recall: 0.59, F1: 0.69\n",
      "\n",
      "\n",
      "\tDETECTOR: openpose\n",
      "\t[face] precision: 0.96, recall: 1.0, F1: 0.98\n",
      "\n",
      "\t[random] precision: 0.72, recall: 0.83, F1: 0.77\n",
      "\n",
      "\n",
      "VID: 061713-1 (400 frames)\n",
      "\tDETECTOR: vj\n",
      "\t[face] precision: 0.94, recall: 0.2, F1: 0.32\n",
      "\n",
      "\t[random] precision: 0.83, recall: 0.06, F1: 0.11\n",
      "\n",
      "\n",
      "\tDETECTOR: mtcnn\n",
      "\t[face] precision: 0.74, recall: 1.0, F1: 0.85\n",
      "\n",
      "\t[random] precision: 0.79, recall: 0.32, F1: 0.46\n",
      "\n",
      "\n",
      "\tDETECTOR: openpose\n",
      "\t[face] precision: 0.78, recall: 1.0, F1: 0.88\n",
      "\n",
      "\t[random] precision: 0.53, recall: 0.99, F1: 0.69\n",
      "\n",
      "\n",
      "VID: 2014-01-01-part2 (400 frames)\n",
      "\tDETECTOR: vj\n",
      "\t[face] precision: 0.85, recall: 0.35, F1: 0.5\n",
      "\n",
      "\t[random] precision: 0.25, recall: 0.03, F1: 0.05\n",
      "\n",
      "\n",
      "\tDETECTOR: mtcnn\n",
      "\t[face] precision: 0.41, recall: 1.0, F1: 0.58\n",
      "\n",
      "\t[random] precision: 0.0, recall: 0.0, F1: 0.0\n",
      "\n",
      "\n",
      "\tDETECTOR: openpose\n",
      "\t[face] precision: 0.49, recall: 1.0, F1: 0.65\n",
      "\n",
      "\t[random] precision: 0.3, recall: 0.89, F1: 0.45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_JSON_PATH  = '/scratch/users/agrawalk/headcam-algo/tests/gold_set_sample.json'\n",
    "display_prf2(SAMPLE_JSON_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
