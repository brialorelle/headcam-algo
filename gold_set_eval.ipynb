{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/users/agrawalk/miniconda2/envs/headcam/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This notebook contains code for drawing face-detected and random samples from a video, \n",
    "annotating on face/no face, and calculating precision, recall, and F-score.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from detector import FaceDetector\n",
    "from gold_sample_processing import (create_sample_json, annotate_sample, run_detector_on_sample, \n",
    "                                    incorporate_openpose_output, display_prf, display_prf2)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!which python # should be /home/users/agrawalk/miniconda2/envs/headcam/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect_faces.py\t\t   haarcascade_frontalface_default.xml\r\n",
      "detect_faces_simple.py\t   irrelevant\r\n",
      "detector.py\t\t   mtcnn\r\n",
      "extract_frames.py\t   openpose_json_output\r\n",
      "gold_sample_processing.py  output\r\n",
      "gold_set_copy.json\t   __pycache__\r\n",
      "gold_set.csv\t\t   snippet.py\r\n",
      "gold_set_eval.ipynb\t   workspace.ipynb\r\n",
      "gold_set.json\t\t   wrap_mtcnn_detect_faces.sh\r\n",
      "gold_set_sample2.json\t   wrap_openpose.sh\r\n",
      "gold_set_sample_copy.json  wrap_snippet.sh\r\n",
      "gold_set_sample.json\t   wrap_test_crop_faces.sh\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "script for detecting faces, given a video frames folder and optionally a max frame length\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process = subprocess.run(['head', '-n', '2', 'detect_faces_simple.py'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "print(process.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am 10 years old\n"
     ]
    }
   ],
   "source": [
    "age=10\n",
    "print(f\"I am {age} years old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. submit job to extract frames with ffmpeg\n",
    "SCRATCH = os.path.expandvars('$SCRATCH')\n",
    "VID_NAMES = ['053113-1', '2014-06-18-part2', '061413-3', '2013-10-27-part2', '061713-1', '2014-01-01-part2']\n",
    "VID_PATHS = [os.path.join(SCRATCH, 'testvideos', f'{vid_name}.AVI' for for vid_name in VID_NAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. submit job to run MTCNN on 10000 frames of each video\n",
    "MASTER_JSON_PATH = os.path.join(SCRATCH, 'headcam-algo/tests/gold_set.json')\n",
    "FRAME_DIRS = [os.path.join(SCRATCH, 'headcam_algo/tests/output', '{}_frames').format(vid_name) for vid_name in VID_NAMES]\n",
    "\n",
    "for frame_dir in FRAME_DIRS:\n",
    "    subprocess.run(['sbatch', '-p', 'normal,hns', '-c', '8', '-t' '4:00:00' \n",
    "                    '--mail-type', 'FAIL', '--mail-user', 'agrawalk@stanford.edu' \n",
    "                    '--wrap', 'python detect_faces_simple.py', frame_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. select a random sample of 200 face, 200 random frames from each video in the JSON\n",
    "SAMPLE_JSON_PATH = '/scratch/users/agrawalk/headcam-algo/tests/gold_set_sample.json'\n",
    "create_sample_json(MASTER_PATH, SAMPLE_PATH, sample_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. run various detectors on the sample\n",
    "run_detector_on_sample('vj', FRAMES_DIR, SAMPLE_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5a. submit job to run openpose on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5b. add columns to the dataframe for the openpose keypoints\n",
    "incorporate_openpose_output(SAMPLE_JSON_PATH, OPENPOSE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMES_DIR = '/scratch/users/agrawalk/headcam-algo/tests/output/'\n",
    "SAMPLE_JSON_PATH  = '/scratch/users/agrawalk/headcam-algo/tests/gold_set_sample.json'\n",
    "annotate_frames(FRAMES_DIR, SAMPLE_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETECTOR: vj\n",
      "\tGROUP: face (1200 frames)\n",
      "\tprecision: 0.94, recall: 0.39, F1: 0.55\n",
      "\n",
      "\tVID: 053113-1 (200 frames)\n",
      "\tprecision: 0.89, recall: 0.65, F1: 0.75\n",
      "\n",
      "\tVID: 2014-06-18-part2 (200 frames)\n",
      "\tprecision: 0.4, recall: 0.03, F1: 0.05\n",
      "\n",
      "\tVID: 061413-3 (200 frames)\n",
      "\tprecision: 1.0, recall: 0.55, F1: 0.71\n",
      "\n",
      "\tVID: 2013-10-27-part2 (200 frames)\n",
      "\tprecision: 0.98, recall: 0.4, F1: 0.56\n",
      "\n",
      "\tVID: 061713-1 (200 frames)\n",
      "\tprecision: 0.94, recall: 0.2, F1: 0.32\n",
      "\n",
      "\tVID: 2014-01-01-part2 (200 frames)\n",
      "\tprecision: 0.85, recall: 0.35, F1: 0.5\n",
      "\n",
      "\tGROUP: random (1200 frames)\n",
      "\tprecision: 0.69, recall: 0.15, F1: 0.25\n",
      "\n",
      "\tVID: 053113-1 (200 frames)\n",
      "\tprecision: 0.47, recall: 0.25, F1: 0.33\n",
      "\n",
      "\tVID: 2014-06-18-part2 (200 frames)\n",
      "\tprecision: 0.0, recall: 0.0, F1: 0.0\n",
      "\n",
      "\tVID: 061413-3 (200 frames)\n",
      "\tprecision: 0.93, recall: 0.25, F1: 0.39\n",
      "\n",
      "\tVID: 2013-10-27-part2 (200 frames)\n",
      "\tprecision: 0.65, recall: 0.22, F1: 0.33\n",
      "\n",
      "\tVID: 061713-1 (200 frames)\n",
      "\tprecision: 0.83, recall: 0.06, F1: 0.11\n",
      "\n",
      "\tVID: 2014-01-01-part2 (200 frames)\n",
      "\tprecision: 0.25, recall: 0.03, F1: 0.05\n",
      "\n",
      "DETECTOR: mtcnn\n",
      "\tGROUP: face (1200 frames)\n",
      "\tprecision: 0.64, recall: 1.0, F1: 0.78\n",
      "\n",
      "\tVID: 053113-1 (200 frames)\n",
      "\tprecision: 0.54, recall: 1.0, F1: 0.7\n",
      "\n",
      "\tVID: 2014-06-18-part2 (200 frames)\n",
      "\tprecision: 0.38, recall: 1.0, F1: 0.55\n",
      "\n",
      "\tVID: 061413-3 (200 frames)\n",
      "\tprecision: 0.98, recall: 1.0, F1: 0.99\n",
      "\n",
      "\tVID: 2013-10-27-part2 (200 frames)\n",
      "\tprecision: 0.81, recall: 1.0, F1: 0.9\n",
      "\n",
      "\tVID: 061713-1 (200 frames)\n",
      "\tprecision: 0.74, recall: 1.0, F1: 0.85\n",
      "\n",
      "\tVID: 2014-01-01-part2 (200 frames)\n",
      "\tprecision: 0.41, recall: 1.0, F1: 0.58\n",
      "\n",
      "\tGROUP: random (1200 frames)\n",
      "\tprecision: 0.71, recall: 0.38, F1: 0.49\n",
      "\n",
      "\tVID: 053113-1 (200 frames)\n",
      "\tprecision: 0.4, recall: 0.57, F1: 0.47\n",
      "\n",
      "\tVID: 2014-06-18-part2 (200 frames)\n",
      "\tprecision: 0.58, recall: 0.31, F1: 0.4\n",
      "\n",
      "\tVID: 061413-3 (200 frames)\n",
      "\tprecision: 0.95, recall: 0.41, F1: 0.57\n",
      "\n",
      "\tVID: 2013-10-27-part2 (200 frames)\n",
      "\tprecision: 0.83, recall: 0.59, F1: 0.69\n",
      "\n",
      "\tVID: 061713-1 (200 frames)\n",
      "\tprecision: 0.79, recall: 0.32, F1: 0.46\n",
      "\n",
      "\tVID: 2014-01-01-part2 (200 frames)\n",
      "\tprecision: 0.0, recall: 0.0, F1: 0.0\n",
      "\n",
      "DETECTOR: openpose\n",
      "\tGROUP: face (1200 frames)\n",
      "\tprecision: 0.8, recall: 1.0, F1: 0.89\n",
      "\n",
      "\tVID: 053113-1 (200 frames)\n",
      "\tprecision: 0.79, recall: 1.0, F1: 0.88\n",
      "\n",
      "\tVID: 2014-06-18-part2 (200 frames)\n",
      "\tprecision: 0.7, recall: 0.97, F1: 0.82\n",
      "\n",
      "\tVID: 061413-3 (200 frames)\n",
      "\tprecision: 0.98, recall: 1.0, F1: 0.99\n",
      "\n",
      "\tVID: 2013-10-27-part2 (200 frames)\n",
      "\tprecision: 0.96, recall: 1.0, F1: 0.98\n",
      "\n",
      "\tVID: 061713-1 (200 frames)\n",
      "\tprecision: 0.78, recall: 1.0, F1: 0.88\n",
      "\n",
      "\tVID: 2014-01-01-part2 (200 frames)\n",
      "\tprecision: 0.49, recall: 1.0, F1: 0.65\n",
      "\n",
      "\tGROUP: random (1200 frames)\n",
      "\tprecision: 0.5, recall: 0.93, F1: 0.65\n",
      "\n",
      "\tVID: 053113-1 (200 frames)\n",
      "\tprecision: 0.26, recall: 0.89, F1: 0.41\n",
      "\n",
      "\tVID: 2014-06-18-part2 (200 frames)\n",
      "\tprecision: 0.44, recall: 0.94, F1: 0.6\n",
      "\n",
      "\tVID: 061413-3 (200 frames)\n",
      "\tprecision: 0.74, recall: 0.97, F1: 0.84\n",
      "\n",
      "\tVID: 2013-10-27-part2 (200 frames)\n",
      "\tprecision: 0.72, recall: 0.83, F1: 0.77\n",
      "\n",
      "\tVID: 061713-1 (200 frames)\n",
      "\tprecision: 0.53, recall: 0.99, F1: 0.69\n",
      "\n",
      "\tVID: 2014-01-01-part2 (200 frames)\n",
      "\tprecision: 0.3, recall: 0.89, F1: 0.45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_JSON_PATH  = '/scratch/users/agrawalk/headcam-algo/tests/gold_set_sample.json'\n",
    "display_prf(SAMPLE_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VID: 053113-1 (400 frames)\n",
      "\tDETECTOR: vj\n",
      "\t[face] precision: 0.89, recall: 0.65, F1: 0.75\n",
      "\n",
      "\t[random] precision: 0.47, recall: 0.25, F1: 0.33\n",
      "\n",
      "\n",
      "\tDETECTOR: mtcnn\n",
      "\t[face] precision: 0.54, recall: 1.0, F1: 0.7\n",
      "\n",
      "\t[random] precision: 0.4, recall: 0.57, F1: 0.47\n",
      "\n",
      "\n",
      "\tDETECTOR: openpose\n",
      "\t[face] precision: 0.79, recall: 1.0, F1: 0.88\n",
      "\n",
      "\t[random] precision: 0.26, recall: 0.89, F1: 0.41\n",
      "\n",
      "\n",
      "VID: 2014-06-18-part2 (400 frames)\n",
      "\tDETECTOR: vj\n",
      "\t[face] precision: 0.4, recall: 0.03, F1: 0.05\n",
      "\n",
      "\t[random] precision: 0.0, recall: 0.0, F1: 0.0\n",
      "\n",
      "\n",
      "\tDETECTOR: mtcnn\n",
      "\t[face] precision: 0.38, recall: 1.0, F1: 0.55\n",
      "\n",
      "\t[random] precision: 0.58, recall: 0.31, F1: 0.4\n",
      "\n",
      "\n",
      "\tDETECTOR: openpose\n",
      "\t[face] precision: 0.7, recall: 0.97, F1: 0.82\n",
      "\n",
      "\t[random] precision: 0.44, recall: 0.94, F1: 0.6\n",
      "\n",
      "\n",
      "VID: 061413-3 (400 frames)\n",
      "\tDETECTOR: vj\n",
      "\t[face] precision: 1.0, recall: 0.55, F1: 0.71\n",
      "\n",
      "\t[random] precision: 0.93, recall: 0.25, F1: 0.39\n",
      "\n",
      "\n",
      "\tDETECTOR: mtcnn\n",
      "\t[face] precision: 0.98, recall: 1.0, F1: 0.99\n",
      "\n",
      "\t[random] precision: 0.95, recall: 0.41, F1: 0.57\n",
      "\n",
      "\n",
      "\tDETECTOR: openpose\n",
      "\t[face] precision: 0.98, recall: 1.0, F1: 0.99\n",
      "\n",
      "\t[random] precision: 0.74, recall: 0.97, F1: 0.84\n",
      "\n",
      "\n",
      "VID: 2013-10-27-part2 (400 frames)\n",
      "\tDETECTOR: vj\n",
      "\t[face] precision: 0.98, recall: 0.4, F1: 0.56\n",
      "\n",
      "\t[random] precision: 0.65, recall: 0.22, F1: 0.33\n",
      "\n",
      "\n",
      "\tDETECTOR: mtcnn\n",
      "\t[face] precision: 0.81, recall: 1.0, F1: 0.9\n",
      "\n",
      "\t[random] precision: 0.83, recall: 0.59, F1: 0.69\n",
      "\n",
      "\n",
      "\tDETECTOR: openpose\n",
      "\t[face] precision: 0.96, recall: 1.0, F1: 0.98\n",
      "\n",
      "\t[random] precision: 0.72, recall: 0.83, F1: 0.77\n",
      "\n",
      "\n",
      "VID: 061713-1 (400 frames)\n",
      "\tDETECTOR: vj\n",
      "\t[face] precision: 0.94, recall: 0.2, F1: 0.32\n",
      "\n",
      "\t[random] precision: 0.83, recall: 0.06, F1: 0.11\n",
      "\n",
      "\n",
      "\tDETECTOR: mtcnn\n",
      "\t[face] precision: 0.74, recall: 1.0, F1: 0.85\n",
      "\n",
      "\t[random] precision: 0.79, recall: 0.32, F1: 0.46\n",
      "\n",
      "\n",
      "\tDETECTOR: openpose\n",
      "\t[face] precision: 0.78, recall: 1.0, F1: 0.88\n",
      "\n",
      "\t[random] precision: 0.53, recall: 0.99, F1: 0.69\n",
      "\n",
      "\n",
      "VID: 2014-01-01-part2 (400 frames)\n",
      "\tDETECTOR: vj\n",
      "\t[face] precision: 0.85, recall: 0.35, F1: 0.5\n",
      "\n",
      "\t[random] precision: 0.25, recall: 0.03, F1: 0.05\n",
      "\n",
      "\n",
      "\tDETECTOR: mtcnn\n",
      "\t[face] precision: 0.41, recall: 1.0, F1: 0.58\n",
      "\n",
      "\t[random] precision: 0.0, recall: 0.0, F1: 0.0\n",
      "\n",
      "\n",
      "\tDETECTOR: openpose\n",
      "\t[face] precision: 0.49, recall: 1.0, F1: 0.65\n",
      "\n",
      "\t[random] precision: 0.3, recall: 0.89, F1: 0.45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_JSON_PATH  = '/scratch/users/agrawalk/headcam-algo/tests/gold_set_sample.json'\n",
    "display_prf2(SAMPLE_JSON_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
