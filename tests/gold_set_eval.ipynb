{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/users/agrawalk/miniconda2/envs/headcam/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This notebook contains code for drawing face-detected and random samples from a video, \n",
    "annotating on face/no face, and calculating precision, recall, and F-score.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import ntpath\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from detector import FaceDetector\n",
    "from ast import literal_eval\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_json(master_json_path, sample_json_path, sample_size=100):\n",
    "    sample_df = pd.DataFrame(columns=['vid_name', 'frame', 'face_mtcnn', 'bb_mtcnn'])\n",
    "    df = pd.read_json(master_json_path)\n",
    "    dfs = [df[df['vid_name'] == vid] for vid in df['vid_name'].unique()]\n",
    "    \n",
    "    sample_df = sample_df.append([df.sample(sample_size) for df in dfs], ignore_index=True)\n",
    "    sample_df = sample_df.append([df[df['face_mtcnn']].sample(sample_size) for df in dfs], ignore_index=True)\n",
    "    \n",
    "    sample_df.to_json(sample_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_num(num):\n",
    "    \"\"\"converts int num to string, and adds zeros to get to length 5, if necessary.\"\"\"\n",
    "    num = str(num)\n",
    "    return '0' * (5 - len(num)) + num     \n",
    "\n",
    "def get_annotation_input():\n",
    "    \"\"\"respond 'y' for face, 'n' or '' for no face, \n",
    "    'g' to go back and re-annotate prev frame\"\"\"\n",
    "    annot = input('Face? (y/[n]/g[o back]) ').lower()\n",
    "    while annot not in ['y', 'n', '', 'g']:\n",
    "        annot = input('Invalid input.\\nFace? (y/[n]/g[o back])').lower()\n",
    "    print('Recorded \\'{}\\''.format(annot))\n",
    "    return annot\n",
    "\n",
    "def annotate_frames(frames_dir, sample_json_path):\n",
    "    \"\"\"Interface for quick annotation of face/no face in sample_frame_dir.\n",
    "    Saves info as 'ground_truth' column in sample frames JSON.\"\"\"\n",
    "    df = pd.read_json(sample_json_path) # assumes a header is already present.\n",
    "    img_paths = [os.path.join(frames_dir, '{0}_frames/image-{1}.jpg'.format(vid_name, format_num(num)))\n",
    "                 for vid_name, num in zip(df['vid_name'], df['frame'])]\n",
    "    imgs = [cv2.imread(path) for path in img_paths]\n",
    "    i = 0\n",
    "    face_present = np.zeros(df['frame'].shape)\n",
    "    print('BEGIN ANNOTATING {}'.format(sample_frame_dir)) \n",
    "    while i < len(imgs):\n",
    "        print('\\nImage {0}/{1}'.format(i + 1, len(imgs)))\n",
    "        plt.imshow(imgs[i])\n",
    "        plt.show()\n",
    "        annot = get_annotation_input()\n",
    "        if annot == 'g':\n",
    "            print('Going back to previous frame')\n",
    "            i -= 1\n",
    "        else:\n",
    "            face_present[i] = (annot == 'y')\n",
    "            i += 1\n",
    "    \n",
    "    df['face_present'] = face_present\n",
    "    print('Saving annotated df')\n",
    "    df.to_json(sample_json_path)\n",
    "    print('Length of annotated df: {}'.format(len(df)))\n",
    "    print('END ANNOTATING {}'.format(frames_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run a detector on frames in sample\n",
    "def run_detector_on_sample(detector_name, frames_dir, sample_json_path):\n",
    "    df = pd.read_json(sample_json_path) # assumes a header is already present.\n",
    "    img_paths = [os.path.join(frames_dir, '{0}_frames/image-{1}.jpg'.format(vid_name, format_num(num)))\n",
    "                 for vid_name, num in zip(df['vid_name'], df['frame'])]\n",
    "    imgs = [cv2.imread(path) for path in img_paths]\n",
    "    \n",
    "    detector = FaceDetector(detector_name)\n",
    "    detections = [detector.detect_faces(img) for img in imgs]\n",
    "    face_detected = [len(faces) > 0 for faces in detections]\n",
    "    df['bb_{}'.format(detector_name)] = detections\n",
    "    df['face_{}'.format(detector_name)] = face_detected\n",
    "    df.to_json(sample_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate/display precision, recall and F-score for each detector\n",
    "#TODO: visualization\n",
    "def display_prf(sample_json_path, det_names = ['vj', 'mtcnn']):\n",
    "    df = pd.read_json(sample_json_path)\n",
    "    true = df[df['face_present']]\n",
    "    \n",
    "    for det_name in det_names:\n",
    "        pos = df[df['face_{}'.format(det_name)]]\n",
    "        true_pos = sel[sel['face_present']]\n",
    "        \n",
    "        p = len(true_pos) / len(pos)\n",
    "        r = len(true_pos) / len(true)\n",
    "        f1 = 2 * p * r / (p + r)\n",
    "        \n",
    "        print('DETECTOR: {}'.format(det_name))\n",
    "        print('positive: {0}, true: {1}, true positive: {2}'.format(len(sel), len(rel), len(true_pos)))\n",
    "        print('precision: {0}, recall: {1}, F1 Score: {2}\\n'.format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pads the number w/ zeros\n",
    "def openpose_format_num(num):\n",
    "    num = str(num)\n",
    "    return '0' * (12 - len(num)) + num    \n",
    "\n",
    "#apply function on each row, return row with openpose info for keypoint\n",
    "def create_openpose_col(row, openpose_dir, keypoint):\n",
    "    fname = '{0}_{1}_keypoints.json'.format(row['vid_name'], \n",
    "                                            openpose_format_num(row['frame'] - 1))\n",
    "    path = os.path.join(openpose_dir, '{}.AVI'.format(row['vid_name']), fname)\n",
    "    op_df = pd.read_json(path)\n",
    "    #list of keypoint-lists\n",
    "    return [person[keypoint] for person in op_df['people'].values] \n",
    "\n",
    "#add openpose columns to dataframe\n",
    "def incorporate_openpose_output(sample_json, openpose_dir):\n",
    "    df = pd.read_json(sample_json)\n",
    "    for keypoint in ['pose_keypoints', 'face_keypoints', 'hand_left_keypoints', 'hand_right_keypoints']:\n",
    "        df[keypoint] = df.apply(lambda row: create_openpose_col(row, openpose_dir, keypoint), axis=1)\n",
    "    df.to_json(sample_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/users/agrawalk/headcam-algo/tests/openpose_json_output/053113-1.AVI/053113-1_000000044346_keypoints.json\n",
      "   version                                             people\n",
      "0        1  {'pose_keypoints': [0, 0, 0, 354.771, 181.313,...\n",
      "/scratch/users/agrawalk/headcam-algo/tests/openpose_json_output/053113-1.AVI/053113-1_000000019093_keypoints.json\n",
      "Empty DataFrame\n",
      "Columns: [version, people]\n",
      "Index: []\n",
      "/scratch/users/agrawalk/headcam-algo/tests/openpose_json_output/061413-3.AVI/061413-3_000000034786_keypoints.json\n",
      "/scratch/users/agrawalk/headcam-algo/tests/openpose_json_output/053113-1.AVI/053113-1_000000044346_keypoints.json\n",
      "   version                                             people\n",
      "0        1  {'pose_keypoints': [0, 0, 0, 354.771, 181.313,...\n",
      "/scratch/users/agrawalk/headcam-algo/tests/openpose_json_output/053113-1.AVI/053113-1_000000019093_keypoints.json\n",
      "Empty DataFrame\n",
      "Columns: [version, people]\n",
      "Index: []\n",
      "/scratch/users/agrawalk/headcam-algo/tests/openpose_json_output/061413-3.AVI/061413-3_000000034786_keypoints.json\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Expected object or value', 'occurred at index 10')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-99f5e4f88522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMASTER_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/scratch/users/agrawalk/headcam-algo/tests/gold_set.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mOPENPOSE_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/scratch/users/agrawalk/headcam-algo/tests/openpose_json_output'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mincorporate_openpose_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMASTER_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPENPOSE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-5e12bba7b331>\u001b[0m in \u001b[0;36mincorporate_openpose_output\u001b[0;34m(sample_json, openpose_dir)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkeypoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'pose_keypoints'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'face_keypoints'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hand_left_keypoints'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hand_right_keypoints'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeypoint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcreate_openpose_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopenpose_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/headcam/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6012\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6013\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6014\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/headcam/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/headcam/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/headcam/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-5e12bba7b331>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkeypoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'pose_keypoints'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'face_keypoints'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hand_left_keypoints'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hand_right_keypoints'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeypoint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcreate_openpose_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopenpose_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-5e12bba7b331>\u001b[0m in \u001b[0;36mcreate_openpose_col\u001b[0;34m(row, openpose_dir, keypoint)\u001b[0m\n\u001b[1;32m      8\u001b[0m                         '{0}_{1}_keypoints.json'.format(row['vid_name'], openpose_format_num(row['frame'] - 1)))\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mop_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mperson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeypoint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mperson\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mop_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'people'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#list of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/headcam/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/headcam/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    527\u001b[0m             )\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/headcam/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'frame'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/headcam/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/headcam/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 853\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             decoded = {str(k): v for k, v in compat.iteritems(\n",
      "\u001b[0;31mValueError\u001b[0m: ('Expected object or value', 'occurred at index 10')"
     ]
    }
   ],
   "source": [
    "MASTER_PATH = '/scratch/users/agrawalk/headcam-algo/tests/gold_set.json'\n",
    "OPENPOSE_DIR = '/scratch/users/agrawalk/headcam-algo/tests/openpose_json_output'\n",
    "incorporate_openpose_output(MASTER_PATH, OPENPOSE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_PATH = '/scratch/users/agrawalk/headcam-algo/tests/gold_set_sample.json'\n",
    "MASTER_PATH = '/scratch/users/agrawalk/headcam-algo/tests/gold_set.json'\n",
    "create_sample_json(MASTER_PATH, SAMPLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1, 2), (5, 6), (1, 2), (5, 6)], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing DataFrame operations\n",
    "sample_df = pd.DataFrame(columns=['vid_name', 'frame', 'face_mtcnn', 'bb_mtcnn'])\n",
    "df2 = pd.DataFrame([[1,2,True,np.array([[4,4,4,4]])],\n",
    "                    [5,6,True,np.array([])]], columns=['vid_name', 'frame', 'face_mtcnn', 'bb_mtcnn'])\n",
    "sample_df = sample_df.append([df2, df2], ignore_index=True)\n",
    "sample_df[sample_df['face_mtcnn']]\n",
    "\n",
    "sample_df.to_json('test.json')\n",
    "sample_df = pd.read_json('test.json')\n",
    "\n",
    "sample_df['bb_mtcnn'][0][0]\n",
    "\n",
    "def test(row):\n",
    "    return row['vid_name'], row['frame']\n",
    "\n",
    "sample_df.apply(test, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('gold_set.json')\n",
    "# df = df[df['vid_name'] != 'toy']\n",
    "print(len(df))\n",
    "# df = df.reset_index(drop=not False)\n",
    "df['frame'].unique()\n",
    "df.info()\n",
    "# df.to_json('gold_set.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
