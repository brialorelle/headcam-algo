---
title: "Preprocess turk annotations ="
output: html_notebook
---


```{r setup, echo = FALSE}
library(knitr)
opts_chunk$set(echo = TRUE)
library(tidyverse)
library(assertthat)
library(ggthemes)
library(lme4)
library(langcog)
library(lmerTest)
library(viridis)
library(magick)
library(egg)
library(jsonlite)
theme_set(theme_few())
```

``
# Preprocessing

```{r}
f <- dir("turk_annotations_segmentation/")
jf <- paste("turk_annotations_segmentation/",f,sep="")
jd <- read_csv(jf)

d.raw <- data.frame()
trial_indexes = seq(1,200,1)
  for (trial_ind in trial_indexes){
    ## get annotation and see if empty
    this_annotation = jd$Answer.annotatedResult.boundingBoxes[trial_ind]
    cleaned_annotation = fromJSON(this_annotation)
    
    # if there was an annotation
    if (length(cleaned_annotation)>1){
        
        ## for each thing that was annotated, new row
        for (annotation_ind in seq(1,length(cleaned_annotation$label),1)){
              trial_data = data.frame(
              label = cleaned_annotation$label[annotation_ind],
              height = cleaned_annotation$height[annotation_ind],
              width = cleaned_annotation$width[annotation_ind],
              left = cleaned_annotation$left[annotation_ind],
              top = cleaned_annotation$top[annotation_ind],
              full_image_path = jd$Input.img_src1[trial_ind],
              trial_number = trial_ind,
              HITID = jd$HITId[trial_ind],
              HITTypeId =jd$HITTypeId[trial_ind],
              WorkerID = jd$WorkerId[trial_ind]
              )
        d.raw <- bind_rows(d.raw, trial_data)
        } # for annotation_ind
    } 
    ## if nothing was annotated
    else{
    trial_data = data.frame(
          ## including HITId and HITTYpe
          label = 'None',
          height = NA,
          width = NA,
          left = NA,
          top = NA,
          full_image_path = jd$Input.img_src1[trial_ind],
          trial_number = trial_ind,
          HITID = jd$HITId[trial_ind],
          HITTypeId =jd$HITTypeId[trial_ind],
          WorkerID = jd$WorkerId[trial_ind]
          )
     d.raw <- bind_rows(d.raw, trial_data)
    }
}
```

## look at distribution of images done per worker
```{r}
worker_summary <- jd %>%
  group_by(WorkerId) %>%
  summarize(count_images = n(), avg_time = mean(WorkTimeInSeconds))
```


```{r}
total_area = jd$Answer.annotatedResult.inputImageProperties.height[1] * jd$Answer.annotatedResult.inputImageProperties.width[1]
d <- d.raw %>%
  mutate(detection_area = (height*width)/total_area)

## plot detection area by detection type
ggplot(d, aes(x=label, y=log(detection_area))) +
  geom_boxplot()

## faces tend to appear towards the top of the image (i.e. 0 pixel coordinates, or upper visual field)
ggplot(d, aes(x=label, y=top)) +
  geom_boxplot()


```

### Write out csv for use in analysis
```{r}
write_csv(d,'turk_segmentations_dec12.csv')
```

```{r}
d <- d %>%
  mutate(short_image_path = str_split_fixed(full_image_path,'/',7)[,7])
```

```{r eval=FALSE}

unique_images = d$full_image_path
for (image in unique_images){
  this_image_rgb <- image_read(image)
  img <- image_draw(this_image_rgb)
  a <- d %>%
    filter(full_image_path %in% image) 
  
  rect(a$left, a$top+a$height, a$left+a$width, a$top)
  text(a$left+10, a$top+10, a$label)
  
  annotated_file = paste0(unique(a$short_image_path), 'turk-annotated.jpg')
  image_write(img, annotated_file)
  dev.off()
}

```

```{r}
faces <- d %>%
  filter(label =="Face") 

rect(faces$left, faces$top+faces$height, faces$left+faces$width, faces$top)
text(faces$left+10, faces$top+10, faces$label)
```

```{r}  
child_hand <- d %>%
  filter(label =="Child hand") 

rect(child_hand$left, child_hand$top+child_hand$height, child_hand$left+child_hand$width, child_hand$top)
text(child_hand$left+10, child_hand$top+10, child_hand$label)



```

