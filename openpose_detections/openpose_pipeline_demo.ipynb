{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import ujson\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections as mc\n",
    "\n",
    "from config import *\n",
    "from openpose_helpers import *\n",
    "from run_openpose import run_openpose\n",
    "\n",
    "print(OUTPUT) \n",
    "# edit OUTPUT in config.py\n",
    "# NOTE: when running on large datasets, make sure this is \n",
    "# a place you have space for millions of tiny files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_OUTPUT = os.path.join(OUTPUT, 'openpose_demo')\n",
    "os.makedirs(DEMO_OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download openpose demo video into demo directory\n",
    "pos_vid_path = os.path.join(DEMO_OUTPUT, 'positive_test_video.avi')\n",
    "neg_vid_path = os.path.join(DEMO_OUTPUT, 'negative_test_video.avi')\n",
    "\n",
    "# Download positive (people in every frame) example video\n",
    "if not os.path.exists(pos_vid_path):\n",
    "    print('Downloading positive video...')\n",
    "    !wget https://github.com/CMU-Perceptual-Computing-Lab/openpose/raw/master/examples/media/video.avi \\\n",
    "        -O $DEMO_OUTPUT/positive_test_video.avi\n",
    "else:\n",
    "    print('Already downloaded positive video')\n",
    "    \n",
    "# Generate negative (no people) video with only black frames\n",
    "if not os.path.exists(neg_vid_path):\n",
    "    print('Generating negative video...')\n",
    "    out = cv2.VideoWriter(neg_vid_path,cv2.VideoWriter_fourcc(*'DIVX'), \n",
    "                          15, (200,200), False)        \n",
    "    black_frame = np.zeros((200,200)).astype('uint8')\n",
    "    img_array = [black_frame] * 10\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()\n",
    "else:\n",
    "    print('Already generated negative video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job to run openpose on this video + condense the outputs into one dataframe\n",
    "op_output_dir = os.path.join(DEMO_OUTPUT, 'openpose_raw_json')\n",
    "condensed_output_dir = os.path.join(DEMO_OUTPUT, 'openpose_condensed')\n",
    "\n",
    "run_openpose(pos_vid_path, op_output_dir, \n",
    "             condensed_output_dir=condensed_output_dir, \n",
    "             keypoint_scale=3, condense=True, overwrite=False)\n",
    "\n",
    "run_openpose(neg_vid_path, op_output_dir, \n",
    "             condensed_output_dir=condensed_output_dir, \n",
    "             keypoint_scale=3, condense=True, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check Openpose by pulling a random frame and seeing if keypoints align with\n",
    "# people's bodies\n",
    "\n",
    "def get_frame(vid_path, frame):\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "    return cap.read()[1]\n",
    "\n",
    "def sanity_check_op_keypts(vid_path, vid_df_path, keypts_normalized=True):\n",
    "    \"\"\"\n",
    "    Given a vid-level JSON, plot a random frame in the video containing openpose \n",
    "    keypoints to sanity-check that the openpose keypoints appear sensible.\n",
    "    \n",
    "    Arguments:\n",
    "    vid_path          -- path to the video to sanity check\n",
    "    vid_df_path       -- path to the video's Openpose condensed \n",
    "                        JSON dataframe to sanity check\n",
    "    keypts_normalized -- True if keypoints in Openpose outputs are normalized\n",
    "    (i.e. x and y values in range [0, 1]), else False\n",
    "    \"\"\"\n",
    "    df = pd.read_json(vid_df_path)\n",
    "    openpose_npy = recover_npy(df)\n",
    "    rand_frame = np.random.randint(0, len(df))\n",
    "    img = get_frame(vid_path, rand_frame)\n",
    "    plt.figure(figsize=(10, img.shape[0]/img.shape[1]*10))\n",
    "    x_factor = img.shape[1] if keypts_normalized else 1\n",
    "    y_factor = img.shape[0] if keypts_normalized else 1\n",
    "    for person in openpose_npy[rand_frame]:\n",
    "        plt.scatter(person[0, NPY_FACE_START:NPY_FACE_END]*x_factor, \n",
    "                    person[1, NPY_FACE_START:NPY_FACE_END]*y_factor, \n",
    "                    c='C0', s=8, label='Face keypoints')\n",
    "        plt.scatter(person[0, NPY_POSE_START:NPY_POSE_END]*x_factor,  \n",
    "                    person[1, NPY_POSE_START:NPY_POSE_END]*y_factor,  \n",
    "                    c='C1', s=8, label='Pose keypoints')\n",
    "        plt.scatter(person[0, NPY_HAND_LEFT_START:NPY_HAND_LEFT_END]*x_factor,   \n",
    "                    person[1, NPY_HAND_LEFT_START:NPY_HAND_LEFT_END]*y_factor,   \n",
    "                    c='C2', s=8, label='Left hand keypoints')\n",
    "        plt.scatter(person[0, NPY_HAND_RIGHT_START:NPY_HAND_RIGHT_END]*x_factor,    \n",
    "                    person[1, NPY_HAND_RIGHT_START:NPY_HAND_RIGHT_END]*y_factor,    \n",
    "                    c='C3', s=8, label='Right hand keypoints')\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())    \n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keypoints appear in sensible places\n",
    "pos_df_path = os.path.join(condensed_output_dir, 'positive_test_video.json')\n",
    "sanity_check_op_keypts(pos_vid_path, pos_df_path, keypts_normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No keypoints appear (since the frame is black and no people detected)\n",
    "neg_df_path = os.path.join(condensed_output_dir, 'negative_test_video.json')\n",
    "sanity_check_op_keypts(neg_vid_path, neg_df_path, keypts_normalized=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (headcam)",
   "language": "python",
   "name": "headcam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
